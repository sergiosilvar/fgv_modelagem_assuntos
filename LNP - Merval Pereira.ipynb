{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import urllib2\n",
      "import nltk\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "import bs4\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Obter coment\u00e1rios do autor.\n",
      "url = 'http://oglobo.globo.com/blogs/blogdomerval/'\n",
      "fname = 'merval_pereira.html'\n",
      "html = urllib2.urlopen(url).read()\n",
      "f = open(fname,'w')\n",
      "f.write(html)\n",
      "f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extrair postagnes do html.\n",
      "\n",
      "\n",
      "f = open(fname,'r')\n",
      "soup = bs4.BeautifulSoup(f)\n",
      "posts = soup.findAll('div', class_='corpoPost')\n",
      "print 'Total de %d postagens.' % len(posts)\n",
      "\n",
      "dates = []\n",
      "docs = []\n",
      "for post in posts:\n",
      "    dates.append(post.find('span', class_='date').string)\n",
      "    docs.append(post.find('div', class_='bodypost').p.text)\n",
      "f.close()\n",
      "del soup,posts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total de 23 postagens.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
      "stop_words.append([u'a',u'\u00e0'])\n",
      "tokenizer = RegexpTokenizer(r'\\w+')\n",
      "antes,depois = [],[]\n",
      "corpus = []\n",
      "for doc in docs:\n",
      "    tokens = tokenizer.tokenize(doc)\n",
      "    tokens = set([token.lower() for token in tokens if token not in stop_words])\n",
      "    corpus.append(tokens)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:9: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Estat\u00edsticas do corpus ap\u00f3s limpeza:'\n",
      "print 'Total de %d documentos.' % len(docs) \n",
      "print u'DocId\\t#Tokens\\t#Voc\u00e1bulos\\t#Caracteres'\n",
      "for i in range(len(docs)):\n",
      "    print '%d\\t%d\\t%d\\t\\t%d'%(i, len(corpus[i]), len(tokenizer.tokenize(docs[i])), len(docs[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estat\u00edsticas do corpus ap\u00f3s limpeza:\n",
        "Total de 23 documentos.\n",
        "DocId\t#Tokens\t#Voc\u00e1bulos\t#Caracteres\n",
        "0\t324\t745\t\t4402\n",
        "1\t316\t728\t\t4279\n",
        "2\t292\t648\t\t3913\n",
        "3\t282\t631\t\t3905\n",
        "4\t299\t664\t\t4000\n",
        "5\t342\t767\t\t4615\n",
        "6\t307\t679\t\t4262\n",
        "7\t262\t592\t\t3639\n",
        "8\t47\t80\t\t506\n",
        "9\t283\t591\t\t3685\n",
        "10\t298\t711\t\t4096\n",
        "11\t313\t740\t\t4305\n",
        "12\t333\t710\t\t4412\n",
        "13\t324\t762\t\t4589\n",
        "14\t214\t461\t\t2734\n",
        "15\t333\t708\t\t4281\n",
        "16\t265\t692\t\t4165\n",
        "17\t319\t676\t\t4180\n",
        "18\t328\t709\t\t4493\n",
        "19\t337\t783\t\t4552\n",
        "20\t305\t638\t\t4030\n",
        "21\t312\t681\t\t4120\n",
        "22\t192\t398\t\t2401\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}